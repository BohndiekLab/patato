{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "769d7b73-0df9-4657-8e5e-047b53e1a13b",
   "metadata": {},
   "source": [
    "# 2. Comparing image reconstruction methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f90696-a7c4-4a18-bb58-6233c12021f2",
   "metadata": {},
   "source": [
    "In this section, we will compare several different image reconstruction methods. Several different methods are available in photoacoustic imaging. Each differs in its complexity, speed and physical basis.\n",
    "\n",
    "PATATO includes two algorithms for image reconstruction, backprojection and a model-based method. Here we will compare the two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1840c918-a354-4ff9-b289-97559f6809ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import patato as pat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b9aff3-72eb-4b3f-b344-bd84df82b793",
   "metadata": {},
   "source": [
    "As an example dataset, we will use a dataset taken from a small-animal photoacoustic scanner (iThera inVision 256-TF, iThera Medical GmbH). We scanned a single slice through a tumour-bearing mouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da4d80ea-d5d4-4fbd-bed7-93cd0ff7f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_data = pat.PAData.from_hdf5(\"data/so2-timeseries-data.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f89a98-e79d-4ef5-bb15-73078124fce0",
   "metadata": {},
   "source": [
    "First we will define a reconstruction grid to directly compare the reconstruction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ae9b7eb-26c0-4f5e-bd30-549603f84a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the reconstruction methods to compare:\n",
    "nx = 101 # number of pixels\n",
    "lx = 2.5e-2 # m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eade1974-a6ef-4a1f-ad0a-ae5f8e1886ae",
   "metadata": {},
   "source": [
    "We will then set up our backprojection reconstruction pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd2d14c-36d7-487a-9d89-961c856eb90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pre-processor for backprojection\n",
    "pre_bp = pat.MSOTPreProcessor(lp_filter=7e6, hp_filter=5e3)\n",
    "\n",
    "ts_bp, settings_bp, _ = pre_bp.run(pa_data.get_time_series(), pa_data)\n",
    "\n",
    "\n",
    "#Â Delay and sum.\n",
    "das = pat.Backprojection(field_of_view=(lx, lx, 0), \n",
    "                             n_pixels=(nx, nx, 1)) # z axis must be specified but is empty in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f105ce1-8033-4c14-9240-1be2da01c7f3",
   "metadata": {},
   "source": [
    "Next, we define out model-based reconstruction pipeline. Here, the program pre-calculates the forward acoustic model matrix, which is then applied in the following step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b05d69-eb17-4373-b795-a1ea72791b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply energy correction to time series data for Model Based reconstruction:\n",
    "ts_model_based = pa_data.get_time_series().copy()\n",
    "ts_model_based.raw_data = ts_model_based.raw_data / pa_data.get_overall_correction_factor()[:, :, None, None]\n",
    "\n",
    "model_based = pat.ModelBasedReconstruction(field_of_view=(lx, lx, 0), \n",
    "                                           n_pixels=(nx, nx, 1), pa_example=pa_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c28645-553b-4041-88c0-d3cbafc782fe",
   "metadata": {},
   "source": [
    "Now, do the image reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adad2cd5-9cae-43dc-80af-0ce6f00a1bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_backprojection, _, _ = das.run(ts_bp, pa_data, **settings_bp)\n",
    "rec_modelbased, _, _ = model_based.run(ts_model_based, pa_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad15c475-be35-4dcc-b29a-a9fb210d8c07",
   "metadata": {},
   "source": [
    "As before, we can plot the reconstructed images from the two approaches and compare them visually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fce92a9-4aa7-4123-86c4-179bf5beaa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "rec_modelbased.imshow(ax = axes[0])\n",
    "axes[0].set_title(\"Model based\")\n",
    "rec_backprojection.imshow(ax = axes[1])\n",
    "axes[1].set_title(\"Backprojection\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
